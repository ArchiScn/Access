# Arch-I-Scan Project Repositories
The Arch-I-Scan Project has aimed to develop a tool for automating the classification of Roman *terra sigillata*, mainly Gaulish.
It comprises material from two sub-projects:
1. The pilot study that used complete/near complete vessels in the collections of the London Museum.
2. The codes and models for the research that used sherds from the collections of MOLA, the Vindolanda Trust, University of Leicester Archaeology Services and the Colchester and Ipswich Museum Services.

## Acknowledgment
The authors would like to thank the Arts and Humanities Research Council (UK) for funding the Arch-I-Scan Project (Grant number AH/T001003/1) and the partner organisations for access to their terra sigillata collections.
 
## Structure of repositories
All files related to the **main sherd project** can be found in [Sherd classification Code and Models](https://github.com/ArchiScn/Sherd_classification_Code_and_Models) repository.  This repository includes all the CNN models, the code to train these models, and the code to generate artificial data for model training.

Files related to **pilot study of using whole vessels** can be found in other three repositories:

1. [Pilot_whole_vessels_Simulated images](https://github.com/ArchiScn/Pilot_whole_vessels_Simulated_images). This repository contains three sets of simulated images used for pre-training of CNN

1. [Pilot_whole_vessels_Collected images](https://github.com/ArchiScn/Pilot_whole_vessels_Collected_images). This repository contains images from The Museum of London antiquarian collection.

1. [Pilot_whole_vessels_Models](https://github.com/ArchiScn/Pilot_whole_vessels_Models) contains some formed CNN models.

The data files for both sub-projects are available on the Archaeology Data Service  - ‘The data archive of the Arch-I-Scan Project’. [***Link will be added later***]

## Publications from the Arch-I-Scan Project
1. Núñez Jareño SJ, van Helden DP, Mirkes EM, Tyukin IY, Allison PM. Learning from scarce information: using synthetic data to classify Roman fine ware pottery. *Entropy*. 23(9), 2021. [DOI:10.3390/e23091140](https://doi.org/10.3390/e23091140)
2. van Helden DP, Mirkes E, Tyukin I and Allison P. The Arch-I-Scan Project: Artificial Intelligence and 3D Simulation for Developing New Approaches to Roman Foodways. *Journal of Computer Applications in Archaeology*, 5(1) 2022, 78–95. [DOI:10.5334/jcaa.92](https://doi.org/10.5334/jcaa.92)
3. Tyukin IY, Tyukina T, van Helden DP, Zheng Z, Mirkes EM, Sutton OJ, Zhou Q, Gorban AN, Allison P. Coping with AI errors with provable guarantees. *Information Sciences*. 678, 2024. [DOI:10.1016/j.ins.2024.120856](https://doi.org/10.1016/j.ins.2024.120856)
4. Tyukin IY, Tyukina T, van Helden D, Zheng Z, Mirkes EM, Sutton OJ, Zhou Q, Gorban AN, Allison P. Weakly Supervised Learners for Correction of AI Errors with Provable Performance Guarantees. *In 2024 International Joint Conference on Neural Networks (IJCNN) IEEE*. 2024. [DOI:10.1109/ijcnn60899.2024.10650338](https://doi.org/10.1109/ijcnn60899.2024.10650338)
5. Tyukin I, Sofeikov K, Levesley J, Gorban AN, Allison P, Cooper NJ. Exploring automated pottery identification [Arch-I-Scan]. Internet Archaeology. 50, 2018. [DOI:10.11141/ia.50.11](https://doi.org/10.11141/ia.50.11)
6. Allison PM., van Helden DP, Tyukin I, Zheng Z. and Tyukina T. The arch-I-scan project: Developing an AI system for identifying and recording roman tablewares. Teaching History, 57(3), 21–26, 2023. Available online [https://search.informit.org/doi/10.3316/informit.322953937064564)](https://search.informit.org/doi/10.3316/informit.322953937064564)
7. van Helden DP and Allison PM. Quantifying pottery: a case study of terra sigillata towards analysing consumption behaviour *American Journal of Archaeology* (in press)

## Citations for the Arch-I-Scan Project Repositories
Please cite this dataset as<br>
Núñez Jareño, S.J.; van Helden, D.P.; Mirkes, E.M.; Zheng, Z.; Tyukina, T.A.; Tyukin, I.Y.; Allison, P. The Arch-I-Scan Project repositories. Available online https://github.com/ArchiScn/Access, 2025.
